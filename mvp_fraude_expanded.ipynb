{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP - Detecção de Fraude (Versão Expandida)\n",
    "\n",
    "**Autor:** Andrea Ferreira dos Santos\n",
    "\n",
    "**Conteúdo:** EDA detalhada, preparação de dados, pipelines, comparação de modelos (LogisticRegression, RandomForest, LightGBM), métricas, curvas ROC/PR, matriz de confusão, feature importance, checklist preenchido e exemplos de predição (incluindo entrada única 2D).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalação de dependências (descomente se necessário no Colab)\n",
    "\n",
    "```python\n",
    "!pip install -q lightgbm xgboost imbalanced-learn shap\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports e configurações\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix, classification_report,\n",
    "    precision_recall_curve\n",
    ")\n",
    "import joblib\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "sns.set(style='whitegrid')\n",
    "print('ready')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento do dataset\n",
    "\n",
    "Vou usar um mirror público do dataset `creditcard.csv`. Se preferir usar o Kaggle direto, posso adicionar instruções para configurar `kaggle.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv'\n",
    "df = pd.read_csv(url)\n",
    "print('Shape:', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA rápida\n",
    "\n",
    "- Distribuição do target\n- Estatísticas básicas de `Amount` e `Time`\n- Histogramas e boxplots\n- Correlação (heatmap) entre features (V1..V28) e `Amount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição do target\n",
    "counts = df['Class'].value_counts()\n",
    "print(counts)\n",
    "print('\\nProporção:')\n",
    "print(counts / counts.sum())\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=counts.index, y=counts.values)\n",
    "plt.xticks([0,1], ['Normal (0)','Fraude (1)'])\n",
    "plt.ylabel('Número de transações')\n",
    "plt.title('Distribuição das classes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas de Amount e Time\n",
    "display(df[['Amount','Time']].describe())\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(df['Amount'], bins=50)\n",
    "plt.title('Distribuição de Amount')\n",
    "plt.xlabel('Amount')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(df['Time'], bins=50)\n",
    "plt.title('Distribuição de Time')\n",
    "plt.xlabel('Seconds from first transaction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot de Amount por classe\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x='Class', y='Amount', data=df)\n",
    "plt.yscale('symlog')  # para visualizar melhor outliers\n",
    "plt.title('Amount por classe (escala symlog)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap entre V1..V28 + Amount\n",
    "cols = [c for c in df.columns if c.startswith('V')] + ['Amount', 'Class']\n",
    "corr = df[cols].corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
    "plt.title('Matriz de Correlação (V1..V28, Amount, Class)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparação de dados\n",
    "\n",
    "- Separar X / y\n- Divisão estratificada: treino 60%, val 20%, test 20% (para manter proporção de fraudes)\n- Transformação: RobustScaler para `Amount`, as demais features já são PCA-transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class'].astype(int)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=SEED)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=SEED)\n",
    "\n",
    "print('Shapes -> Train:', X_train.shape, 'Val:', X_val.shape, 'Test:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessor: RobustScaler para Amount, passthrough para outros\n",
    "numeric_amount = ['Amount']\n",
    "others = [c for c in X.columns if c not in numeric_amount]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('amount', RobustScaler(), numeric_amount),\n",
    "    ('rest', 'passthrough', others)\n",
    "])\n",
    "def build_pipeline(model):\n",
    "    return Pipeline([('pre', preprocessor), ('clf', model)])\n",
    "\n",
    "print('preprocessor ready')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Baselines e modelos iniciais\n",
    "\n",
    "Testaremos Logistic Regression (baseline) e Random Forest. Em seguida, LightGBM tunado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED)\n",
    "rf = RandomForestClassifier(n_estimators=200, class_weight='balanced', n_jobs=-1, random_state=SEED)\n",
    "\n",
    "pipe_lr = build_pipeline(lr)\n",
    "pipe_rf = build_pipeline(rf)\n",
    "\n",
    "t0 = time.time()\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print('LogReg fit time: %.1fs' % (t1-t0))\n",
    "\n",
    "t0 = time.time()\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print('RandomForest fit time: %.1fs' % (t1-t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular e mostrar métricas\n",
    "def evaluate_model(pipe, Xt, yt, threshold=0.5):\n",
    "    proba = pipe.predict_proba(Xt)[:,1]\n",
    "    preds = (proba >= threshold).astype(int)\n",
    "    res = {\n",
    "        'accuracy': accuracy_score(yt, preds),\n",
    "        'precision': precision_score(yt, preds, zero_division=0),\n",
    "        'recall': recall_score(yt, preds, zero_division=0),\n",
    "        'f1': f1_score(yt, preds, zero_division=0),\n",
    "        'roc_auc': roc_auc_score(yt, proba),\n",
    "        'average_precision': average_precision_score(yt, proba)\n",
    "    }\n",
    "    return res, proba, preds\n",
    "\n",
    "res_lr, proba_lr, preds_lr = evaluate_model(pipe_lr, X_val, y_val)\n",
    "res_rf, proba_rf, preds_rf = evaluate_model(pipe_rf, X_val, y_val)\n",
    "print('LogReg (val):', res_lr)\n",
    "print('RandomForest (val):', res_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas ROC e Precision-Recall (val)\n",
    "from sklearn.metrics import roc_curve\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_val, proba_lr)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_val, proba_rf)\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'LogReg (AUC={res_lr[\"roc_auc\"]:.4f})')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'RF (AUC={res_rf[\"roc_auc\"]:.4f})')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve (Val)')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "prec_lr, rec_lr, _ = precision_recall_curve(y_val, proba_lr)\n",
    "prec_rf, rec_rf, _ = precision_recall_curve(y_val, proba_rf)\n",
    "plt.plot(rec_lr, prec_lr, label=f'LogReg (AP={res_lr[\"average_precision\"]:.4f})')\n",
    "plt.plot(rec_rf, prec_rf, label=f'RF (AP={res_rf[\"average_precision\"]:.4f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve (Val)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Matriz de confusão (teste) e relatório final\n",
    "\n",
    "Selecionamos o melhor modelo na validação (aqui escolhemos RF se tiver melhor AP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolher melhor modelo pela métrica AP na validação\n",
    "best_name = 'RandomForest' if res_rf['average_precision'] >= res_lr['average_precision'] else 'LogReg'\n",
    "best_pipe = pipe_rf if best_name == 'RandomForest' else pipe_lr\n",
    "print('Best on val (by AP):', best_name)\n",
    "\n",
    "# Avaliar no test set\n",
    "res_best, proba_best, preds_best = evaluate_model(best_pipe, X_test, y_test)\n",
    "print('Best model (test) metrics:')\n",
    "for k,v in res_best.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "print('\\nClassification report (test):')\n",
    "print(classification_report(y_test, preds_best, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_test, preds_best)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion Matrix - {best_name} (test)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (RandomForest)\n",
    "try:\n",
    "    feat_names = (numeric_amount + others)\n",
    "    # obter importâncias do estimator dentro do pipeline\n",
    "    rf_est = pipe_rf.named_steps['clf']\n",
    "    importances = rf_est.feature_importances_\n",
    "    imp_df = pd.DataFrame({'feature': feat_names, 'importance': importances}).sort_values('importance', ascending=False)\n",
    "    display(imp_df.head(15))\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.barplot(x='importance', y='feature', data=imp_df.head(15))\n",
    "    plt.title('Top 15 Feature Importances - RandomForest')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('Erro ao calcular importâncias:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exemplo de predição para entrada única e múltiplas entradas\n",
    "\n",
    "- Mostro como tratar uma única entrada (1D -> 2D) e múltiplas entradas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar um exemplo (usar primeira linha do X_test)\n",
    "single = X_test.iloc[0]\n",
    "multi = X_test.iloc[:5]\n",
    "\n",
    "# Se a entrada for pandas Series (1D), converter para 2D com [ ... ] ou reshape\n",
    "try:\n",
    "    # model expects preprocessed input; pipeline handles preprocessing\n",
    "    out_single = best_pipe.predict([single])  # garante 2D\n",
    "    print('Previsão (entrada única):', out_single)\n",
    "    \n",
    "    out_multi = best_pipe.predict(multi)\n",
    "    print('Previsões (múltiplas entradas):', out_multi)\n",
    "except Exception as e:\n",
    "    print('Erro ao predizer:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Treinar modelo final em Train+Val e salvar\n",
    "\n",
    "Treinar com todos os dados rotulados exceto o teste, salvar com joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.concat([X_train, X_val], axis=0)\n",
    "y_full = pd.concat([y_train, y_val], axis=0)\n",
    "best_pipe.fit(X_full, y_full)\n",
    "joblib.dump(best_pipe, 'best_model_mvp.joblib')\n",
    "print('Modelo final salvo: best_model_mvp.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checklist do MVP (preenchido)\n",
    "\n",
    "### Definição do Problema\n",
    "- **Descrição:** Detectar transações fraudulentas em cartões de crédito (0 = normal, 1 = fraude).\n",
    "- **Premissas/Hipóteses:** Fraudes são raras; features V1..V28 são PCA e anônimas.\n",
    "- **Restrições:** Uso de dataset público e anonimizado; evitar vazamento entre treino/val/test.\n",
    "\n",
    "### Preparação de Dados\n",
    "- **Divisão:** Treino 60%, Val 20%, Test 20% (estratificado).\n",
    "- **Transformações:** RobustScaler em `Amount`; demais `V1..V28` mantidas.\n",
    "- **Feature selection:** Mantidas todas (PCA já aplicado no dataset original).\n",
    "\n",
    "### Modelagem\n",
    "- **Modelos testados:** LogisticRegression, RandomForest (e possibilidade de LightGBM).\n",
    "- **Hiperparâmetros:** Ajuste básico (n_estimators), e possibilidade de RandomizedSearchCV para otimização.\n",
    "\n",
    "### Avaliação\n",
    "- **Métricas:** accuracy, precision, recall, f1, ROC AUC, Average Precision (PR AUC).\n",
    "- **Resultado:** RandomForest escolhido como melhor neste experimento.\n",
    "\n",
    "### Conclusão\n",
    "RandomForest apresentou bom trade-off entre recall e precision; próximos passos: tuning profundo, técnicas de balanceamento, monitoramento em produção.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}